{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOVFFOZ/wUq1Vq/eDYJ0FXE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install pycuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PnZpvdeVQgxv","executionInfo":{"status":"ok","timestamp":1732923133720,"user_tz":300,"elapsed":146002,"user":{"displayName":"JUAN FELIPE BETANCUR GOMEZ","userId":"04766957144430832553"}},"outputId":"dafee50e-e5e0-486b-f15b-67e34c4af389"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pycuda\n","  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytools>=2011.2 (from pycuda)\n","  Downloading pytools-2024.1.17-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n","Collecting mako (from pycuda)\n","  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n","Downloading pytools-2024.1.17-py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pycuda\n","  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=660545 sha256=ebc0718a52411c62045dc570ff0fd9d4044cda4ca6475943d1d46bc55832adf7\n","  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n","Successfully built pycuda\n","Installing collected packages: pytools, mako, pycuda\n","Successfully installed mako-1.3.6 pycuda-2024.1.2 pytools-2024.1.17\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pycuda.driver as cuda\n","import pycuda.autoinit\n","from pycuda.compiler import SourceModule\n","import matplotlib.pyplot as plt\n","import time\n","from datetime import datetime\n","\n","# CUDA kernel for dotplot calculation\n","cuda_kernel = \"\"\"\n","__global__ void dotplot_kernel(unsigned char* seq1_chunk, unsigned char* seq2,\n","                                bool* result, int chunk_len, int seq1_len, int seq2_len,\n","                                int start_idx) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < chunk_len && col < seq2_len) {\n","        result[row * seq2_len + col] = (seq1_chunk[row] == seq2[col]);\n","    }\n","}\n","\"\"\"\n","\n","def load_sequence(filename):\n","    \"\"\"Load FASTA sequence and preprocess.\"\"\"\n","    with open(filename, 'r') as file:\n","        seq = file.read()\n","\n","    # Remove first line and line breaks\n","    seq = ''.join(seq.split('\\n')[1:])\n","\n","    # Create numpy array and map to integers\n","    mapping = {'A': 0, 'C': 1, 'G': 2, 'N': 3, 'T': 4}\n","    seq_array = np.array(list(seq))\n","    return np.vectorize(mapping.get)(seq_array).astype('uint8')\n","\n","def cuda_dotplot_chunked(seq1, seq2, result_filename, num_chunks=10):\n","    \"\"\"Perform CUDA-accelerated dotplot calculation with chunked processing.\"\"\"\n","    seq1_len, seq2_len = len(seq1), len(seq2)\n","\n","    # Create memory-mapped file for results\n","    result_map = np.memmap(result_filename, dtype='bool', mode='w+', shape=(seq1_len, seq2_len))\n","\n","    # Calculate chunk size\n","    chunk_size = seq1_len // num_chunks\n","\n","    # Allocate device memory for seq2 (constant across chunks)\n","    seq2_gpu = cuda.mem_alloc(seq2.nbytes)\n","    cuda.memcpy_htod(seq2_gpu, seq2)\n","\n","    # Compile CUDA kernel\n","    mod = SourceModule(cuda_kernel)\n","    dotplot_kernel = mod.get_function(\"dotplot_kernel\")\n","\n","    # Setup grid and block dimensions\n","    block_size = 32\n","    grid_x = (seq2_len + block_size - 1) // block_size\n","\n","    # Process seq1 in chunks\n","    for i in range(num_chunks):\n","        # Calculate chunk indices\n","        start_idx = i * chunk_size\n","        end_idx = start_idx + chunk_size if i != num_chunks - 1 else seq1_len\n","\n","        # Current chunk\n","        seq1_chunk = seq1[start_idx:end_idx]\n","        chunk_len = len(seq1_chunk)\n","\n","        # Allocate device memory for current chunk\n","        seq1_chunk_gpu = cuda.mem_alloc(seq1_chunk.nbytes)\n","        cuda.memcpy_htod(seq1_chunk_gpu, seq1_chunk)\n","\n","        # Allocate device memory for chunk result\n","        result_chunk_gpu = cuda.mem_alloc(chunk_len * seq2_len * np.dtype('bool').itemsize)\n","\n","        # Calculate grid dimensions for current chunk\n","        grid_y = (chunk_len + block_size - 1) // block_size\n","\n","        # Launch kernel\n","        dotplot_kernel(\n","            seq1_chunk_gpu, seq2_gpu, result_chunk_gpu,\n","            np.int32(chunk_len), np.int32(seq1_len), np.int32(seq2_len),\n","            np.int32(start_idx),\n","            block=(block_size, block_size, 1),\n","            grid=(grid_x, grid_y)\n","        )\n","\n","        # Allocate host buffer for this chunk\n","        result_chunk = np.zeros((chunk_len, seq2_len), dtype=bool)\n","\n","        # Copy result back to host\n","        cuda.memcpy_dtoh(result_chunk, result_chunk_gpu)\n","\n","        # Write chunk to memory-mapped file\n","        result_map[start_idx:end_idx, :] = result_chunk\n","\n","    return result_map\n","\n","def plot_dotplot(result_filename, seq1_len, seq2_len):\n","    \"\"\"Plot the dot plot from memory-mapped file.\"\"\"\n","    result_map = np.memmap(result_filename, dtype='bool', mode='r', shape=(seq1_len, seq2_len))\n","    plt.figure(figsize=(10, 10))\n","    plt.title(\"Dotplot CUDA\")\n","    plt.xlabel(\"Seq2\")\n","    plt.ylabel(\"Seq1\")\n","    plt.imshow(result_map[:500, :500], cmap='binary', aspect='auto')\n","    plt.savefig(\"ResultadoCUDA.png\")\n","    plt.close()\n","\n","def main():\n","    # Start timing\n","    begin = time.time()\n","    print(datetime.today())\n","\n","    # Load sequences\n","    seq1 = load_sequence('sample_data/archivos_dotplot/elemento1.fasta')\n","    seq2 = load_sequence('sample_data/archivos_dotplot/elemento2.fasta')\n","\n","    # Result filename for memory mapping\n","    result_filename = './dotplot_result_cuda.dat'\n","\n","    # Perform CUDA dotplot calculation with chunked memory processing\n","    result_map = cuda_dotplot_chunked(seq1, seq2, result_filename)\n","\n","    # Plot result\n","    plot_dotplot(result_filename, len(seq1), len(seq2))\n","\n","    # Cleanup (close the memory-mapped file)\n","    del result_map\n","\n","    # End timing\n","    end = time.time()\n","    print(datetime.today())\n","    print(f\"Tiempo de ejecución CUDA: {end-begin} segundos\")\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGx7OytgQg1X","executionInfo":{"status":"ok","timestamp":1732923762996,"user_tz":300,"elapsed":161814,"user":{"displayName":"JUAN FELIPE BETANCUR GOMEZ","userId":"04766957144430832553"}},"outputId":"ac3e35e7-1824-48d7-a80e-8d19ddb4b09e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-29 23:40:01.130964\n","2024-11-29 23:42:42.544526\n","Tiempo de ejecución CUDA: 161.41354513168335 segundos\n"]}]}]}